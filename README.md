# 🛠️ CADQuery Code Generation - GenCAD Challenge Submission

## 🧪 The Task
Create the best CadQuery code generator model.

![](assets/Screenshot 2025-06-24 195709.png)

### Challenge Steps:
1. Load the dataset (147K pairs of Images/CadQuery code).
2. Create a baseline model and evaluate it with the given metrics.
3. Enhance the baseline model by any means and evaluate again.
4. Explain your choices and potential bottlenecks.
5. Show what enhancements you would have done with more time.

> 💡 Creativity and methodology matter more than absolute results!

---

## 📚 Step 1: Literature-Informed Design

After reviewing recent works and their approaches (see the table below), the following insights informed our methodology:

### Notable References:
- GenCAD & CSGNet use custom architectures trained from scratch
- CAD-Coder (LLaVA 1.5) fine-tunes vision-language models
- LLM4CAD, CAD-Assistant rely on GPT-4(o) with tool augmentation

Our goal: develop a **practical**, **open**, and **extensible** solution that aligns with CadQuery’s structure, and is trainable on commodity GPUs.

![model comparison table](assets/Screenshot 2025-06-24 195759.png)


Source: Doris, A. C., Alam, M. F., Nobari, A. H., & Ahmed, F. (2025, May 20). CAD-Coder: An Open-Source Vision-Language model for Computer-Aided design code generation. [arXiv:2505.14646](https://arxiv.org/abs/2505.14646)

---

## ⚙️ Step 2: Baseline Model - Vision Encoder + GPT-2

We developed a simple, extensible baseline based on:

- 🎞️ **Visual Encoder**: Pretrained ResNet18 for grayscale CAD image embeddings
- 🧠 **Language Decoder**: GPT-2 (gpt2) autoregressive transformer
- 🔗 **Fusion**: Visual embeddings projected to token space and prepended

### 🚨 Limitations
- GPT-2 struggles with indentation-sensitive Python code
- Frequent CadQuery syntax errors
- Lacks code-specific pretraining

---

## 🔁 Step 3: Enhancement with Salesforce CodeGen

### Why `Salesforce/codegen-350M-mono`?
- ✅ **Tailored for code generation** (unlike GPT-2)
- 🔧 **Monolingual Python** model (perfect for CadQuery DSL)
- 📈 **Better results on syntax-aware metrics** (e.g., VSR, IoU)
- 🧠 **Lightweight & fine-tunable** on a single GPU
- 🔄 **Compatible with self-debugging loops** to repair code

This resulted in higher Valid Syntax Rates and improved geometric alignment.

---

## 🔎 Step 4: Bottlenecks and Observations

### Bottlenecks:
- ❌ Lack of loop context or multiple-sketch memory
- ⌛ Limited training time for full convergence
- ⚠️ Errors in `loop1` generation not resolved without reference tracking
- 🧠 Visual encoder not fine-tuned with decoder jointly (yet)

---

## 🚀 Step 5: Future Enhancements (from GenCAD repo)

Based on the official [GenCAD repository](https://github.com/ferdous-alam/GenCAD), next steps include:

- 🔄 **Train ResNet + Decoder jointly** for better alignment
- 📐 **Use multi-sketch memory** or recurrence for CAD programs with multiple operations
- 🛠️ **Implement CAD-Code-aware loss** using structural program diffs
- 🧪 **Pretrain with synthetic CAD corpus** before fine-tuning on GenCAD
- 🎓 **Use tool-augmented LLMs** (e.g. GPT4-o + debugger)
- 🎯 **Evaluation with execution-based metrics** (e.g., rendered IoU)

---

## ✅ Conclusion
This project demonstrates a full training loop, from baseline GPT-2 to CodeGen-based enhancement. While absolute metrics remain improvable, the architecture choices and pipeline provide a solid foundation for real-world CAD code generation.

### Everything is explained in the `good_luck.ipynb` notebook as well.
